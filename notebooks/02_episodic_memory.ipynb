{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50ef609-efa4-408f-859a-db1128006a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/asaduakas/ml_env/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/asaduakas/ml_env/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: packaging in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (4.56.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: scipy in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sentence-transformers) (0.35.0)\n",
      "Requirement already satisfied: filelock in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: requests in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: sympy in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: networkx in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/asaduakas/ml_env/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c148d27-2713-4a99-839c-147a2f162785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bf7c12-64ed-4468-905b-5ed8a22047e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "memory_texts = []\n",
    "metadata_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5a496-313d-498b-bf33-a9f1419a9681",
   "metadata": {},
   "source": [
    "`d` is the dimension of embedding and `IndexFlatIP` is inner product or dot product. Note, embeddings must be normalized in order compute cosine similarity this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b06901-43d5-49ff-ab8d-72f1579a9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 384\n",
    "index = faiss.IndexFlatIP(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089eac3b-6c06-43bb-89d3-6586d99da2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_turn(text, players=[], npcs=[], tags=[], scene_id=None):\n",
    "    embedding = model.encode([text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    index.add(embedding)\n",
    "    memory_texts.append(text)\n",
    "    metadata = {\n",
    "        \"text\": text,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"players\": players,\n",
    "        \"npcs\": npcs,\n",
    "        \"tags\": tags,\n",
    "        \"scene_id\": scene_id\n",
    "    }\n",
    "    metadata_list.append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a2ea7a-9828-48d2-9e2b-749ca4ea4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_memory(query_text, top_k=3):\n",
    "    \"\"\"\n",
    "    Query the memory index using a text string and return the top_k most similar entries\n",
    "    based on cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): The text to search for in memory.\n",
    "        top_k (int, optional): Number of top results to return. Defaults to 3.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of results with text, similarity score, and metadata.\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode(\n",
    "        [query_text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    similarity_scores, memory_indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = [\n",
    "        {\n",
    "            \"text\": memory_texts[idx],\n",
    "            \"similarity\": float(score),\n",
    "            \"metadata\": metadata_list[idx]\n",
    "        }\n",
    "        for idx, score in zip(memory_indices[0], similarity_scores[0])\n",
    "    ]\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4065e9e6-065b-4e91-9219-4793881da467",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_turn(\"Player1 opened the treasure chest\", \n",
    "         players=[\"Player1\"], \n",
    "         npcs=[], \n",
    "         tags=[\"exploration\"], \n",
    "         scene_id=1)\n",
    "add_turn(\"The party killed the dragon\",\n",
    "         players=[\"Player1\",\"Player2\",\"Player3\"],\n",
    "         npcs=[\"Dragon\"],\n",
    "         tags=[\"combat\"],\n",
    "         scene_id=2)\n",
    "add_turn(\"Wizard asked to kill the bandits.\",\n",
    "         players=[\"Player1\",\"Player2\",\"Player3\"],\n",
    "         npcs=[\"Wizard\"],\n",
    "         tags=[\"quest\"],\n",
    "         scene_id=3)\n",
    "add_turn(\"Bandits attacked the village\",\n",
    "         players=[],\n",
    "         npcs=[\"Bandits\"],\n",
    "         tags=[\"dialogue\"],\n",
    "         scene_id=4)\n",
    "add_turn(\"Player2 stole the key.\",\n",
    "         players=[\"Player2\"],\n",
    "         npcs=[\"Guard\"],\n",
    "         tags=[\"exploration\"],\n",
    "         scene_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea4c863-bcae-4f91-90ad-60d47d17f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: Player2 stole the key. | Similarity=0.75 | Metadata={'text': 'Player2 stole the key.', 'timestamp': '2025-10-01T12:44:27.648091', 'players': ['Player2'], 'npcs': ['Guard'], 'tags': ['exploration'], 'scene_id': 5}\n",
      "Match: Player1 opened the treasure chest | Similarity=0.39 | Metadata={'text': 'Player1 opened the treasure chest', 'timestamp': '2025-10-01T12:44:27.608449', 'players': ['Player1'], 'npcs': [], 'tags': ['exploration'], 'scene_id': 1}\n"
     ]
    }
   ],
   "source": [
    "query_results = query_memory(\"Who stole the key?\", top_k=2)\n",
    "\n",
    "for r in query_results:\n",
    "    print(f\"Match: {r['text']} | Similarity={r['similarity']:.2f} | Metadata={r['metadata']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceba3d7-8c0e-48f8-986b-e61dd91521cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dm_prompt(player_action, retrieved_memories, world_state):\n",
    "    memory_texts = \"\\n\".join([m[\"text\"] for m in retrieved_memories])\n",
    "    world_facts = \"\\n\".join([f\"{k}: {v}\" for k, v in world_state.items()])\n",
    "    return f\"\"\"\n",
    "You are a Dungeon Master running a fantasy campaign.\n",
    "You must be consistent with past events and the current world state.\n",
    "Respond to player's action like a Dungen Master would.\n",
    "Tell them the consequences of their actions and make it like you are reading from fantasy book.\n",
    "\n",
    "--- World Facts ---\n",
    "{world_facts}\n",
    "\n",
    "--- Relevant Past Memories ---\n",
    "{memory_texts}\n",
    "\n",
    "--- Player Action ---\n",
    "{player_action}\n",
    "\n",
    "--- Your Task ---\n",
    "1. Narrate what happens next in a dramatic but concise way.\n",
    "2. Roleplay any NPCs if they are involved.\n",
    "3. Do NOT contradict the memories or world facts.\n",
    "4. Keep tone consistent with a fantasy Dungeon Master.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd994b-5f24-4768-bbf2-e7891656395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_state = {\n",
    "    \"location\": \"Dark Cave\",\n",
    "    \"npc\": \"\",\n",
    "    \"quest\": \"Retrieve the treasure\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e164b9b-72ea-4aad-84b1-b73394341bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_action = \"I look inside the treasure chest to see what's in there!\"\n",
    "retrieved = query_memory(player_action, top_k=3)\n",
    "prompt = build_dm_prompt(player_action, retrieved, world_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874543b-f052-4cc1-90ee-069390be29a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a81cde407314d8b96a10291d9d40428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26973c53378b4316b88dc4b0d5d15b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305a90b70c7146de88212b6deee818b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd00ee7946b48fbaa57f8093bd535b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d13cc47d4bf440db50894cda37396b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee98941a65404f03bcbf2344b05929eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c6d97c14654f99a3539abe703687da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455436cfb02742389e3d36257f1236e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a9eb8b703e40f185013aa2948bd4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692e2e5add414ef785c583d6b1e0c574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c026ebdf77247bba87f64c3dff9711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaafcf27f5947208923066127fb7002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a6e399cad447f296119bb29a6f3d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4f986eac40465289dd1e75b383cf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20afca2b9f7b401b8ee751aa4acd5e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "cache_dir = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "print(f\"Model cached at: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24abe250-6170-46e6-8689-84404b8dfa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace/envs/dnd/lib/python3.12/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1755b4710a4339a38d24fc12e96dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a Dungeon Master running a fantasy campaign.\n",
      "You must be consistent with past events and the current world state.\n",
      "Respond to player's action like a Dungen Master would.\n",
      "Tell them the consequences of their actions and make it like you are reading from fantasy book.\n",
      "\n",
      "--- World Facts ---\n",
      "location: Dark Cave\n",
      "npc: \n",
      "quest: Retrieve the treasure\n",
      "\n",
      "--- Relevant Past Memories ---\n",
      "Player1 opened the treasure chest\n",
      "Player2 stole the key.\n",
      "Wizard asked to kill the bandits.\n",
      "\n",
      "--- Player Action ---\n",
      "I look inside the treasure chest to see what's in there!\n",
      "\n",
      "--- Your Task ---\n",
      "1. Narrate what happens next in a dramatic but concise way.\n",
      "2. Roleplay any NPCs if they are involved.\n",
      "3. Do NOT contradict the memories or world facts.\n",
      "4. Keep tone consistent with a fantasy Dungeon Master.\n",
      "\n",
      "--- Output ---\n",
      "You open the chest to reveal a pile of coins and a key!\n",
      "\"Hey, that's my key!\" Player2 shouts.\n",
      "\"Hey, I'm the wizard! Kill the bandits!\" the wizard replies.\n",
      "\n",
      "--- Answer Key ---\n",
      "1. I open the chest to reveal a pile of coins and a key!\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "5.\n",
      "\n",
      "--- Answer ---\n",
      "1. I\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\",model=cache_dir, device_map=\"auto\")\n",
    "outputs = pipe(prompt, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
